{"cells":[{"cell_type":"markdown","metadata":{"id":"v3yYLRWg77CP"},"source":["# Sentence Classification with Huggingface-Trainer\n","\n","Creators: Luca Moroni\n","\n","Official Reference: https://huggingface.co/blog/sentiment-analysis-python\n","\n","To face this notebook you must read and understand well the \"NLP Notebook #5 - Transformers\".\n","\n","In this EXTRA notebook we will see the usage of Huggingface Trainer, a tested pipeline that led us to use less code and concentrate on other aspects than create the wheel again every times (e.g. training for loop, early stopping, ...).\n","\n","\n","Let's go through the code!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from typing import Dict\n","import torch\n","from datasets import load_dataset\n","from transformers import DataCollatorWithPadding\n","\n","from datasets import load_dataset\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    EvalPrediction,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n",")"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"CDVJcVjPK-jp"},"outputs":[],"source":["\n","\n","\n","### Model Parameters\n","# we will use with Distil-BERT\n","language_model_name = \"roberta-base\"\n","\n","### Training Argurments\n","\n","# this GPU should be enough for this task to handle 32 samples per batch\n","batch_size = 8\n","\n","# optim\n","learning_rate = 1e-4\n","weight_decay = 0.001 # we could use e.g. 0.01 in case of very low and very high amount of data for regularization\n","\n","# training\n","epochs = 1\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","\n","set_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"IIxu6PrUkb1k"},"source":["In this example we will use **Sentiment Tree Bank corpus (SST2)**, one of the main benchmark for binary sentiment analysis task.\n","\n","The dataset if freely available through Huggingface Datasets."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6887,"status":"ok","timestamp":1716454815232,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"1rFUoPr5DS50","outputId":"da3f8566-37f1-40ed-9964-f6c068c3d460"},"outputs":[],"source":["# load our dataset\n","sst2_dataset = load_dataset(\"stanfordnlp/sst2\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716454815232,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"8yvWohoaDVKs","outputId":"fcb403f0-544e-438d-9cfa-f0b28c9ca5bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: as they come , already having been recycled more times than i 'd care to count \n","Sentiment: Negative\n"]}],"source":["## Let's see an example...\n","print(f\"Sentence: {sst2_dataset['train']['sentence'][42]}\")\n","print(f\"Sentiment: {'Positive' if sst2_dataset['train']['label'][42] == 1 else 'Negative'}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1716454815232,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"fb4h4PlNDcNl","outputId":"df0748eb-8f14-4b46-bcc3-7ee7ed2dadb9"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['idx', 'sentence', 'label'],\n","        num_rows: 67349\n","    })\n","    validation: Dataset({\n","        features: ['idx', 'sentence', 'label'],\n","        num_rows: 872\n","    })\n","    test: Dataset({\n","        features: ['idx', 'sentence', 'label'],\n","        num_rows: 1821\n","    })\n","})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["## The structure of the huggingface dataset.\n","## Here the test set cannot be used since is a blind test set, so there aren't the gold labels.\n","sst2_dataset"]},{"cell_type":"markdown","metadata":{"id":"5zxaIw4Zljkn"},"source":["### Metric Definition\n","\n","Looking only at cross entropy loss cannot allow us to understand effectivelly the real capabilities of our NLP model. So let's define a standard method to compute:\n","\n","- **Accuracy** metric\n","- **F1** metric"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UnQC7RJhJU1l"},"outputs":[],"source":["from datasets import load_metric\n","\n","# Metrics\n","\n","def compute_metrics(eval_pred):\n","   load_accuracy = load_metric(\"accuracy\")\n","   load_f1 = load_metric(\"f1\")\n","\n","   logits, labels = eval_pred\n","   predictions = np.argmax(logits, axis=-1)\n","   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n","   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n","   return {\"accuracy\": accuracy, \"f1\": f1}"]},{"cell_type":"markdown","metadata":{"id":"PVA0rQ6dmhdX"},"source":["## The Model\n","\n","We will rely on the Huggingface **AutoModelForSequenceClassification** class from huggingface repository. This is a wrapper for encoder-only models, that allow us to simply create a model suitable to solve a classification task over textual sentences.\n","\n","### Sentence Classification\n","\n","In the previous notebook you saw how to train a token level classifier to solve NER task, learning a MLP over each tokens of the input sentence. In the setting of sentence level classification the standard approaches apply a MLP over the [CLS] token's embedding of the last encoder layer. This is because the [CLS] token contains a lot of information about the **semantic and syntactitc** structure of the input sentence.\n","\n","![alt text](https://jalammar.github.io/images/bert-classifier.png \"Sentence Classification\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2024,"status":"ok","timestamp":1716454868624,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"BaeWJQhKtZ1H","outputId":"09c9c6b7-17af-48f8-bf0a-a5b577bb3ef4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["## Initialize the model\n","model = AutoModelForSequenceClassification.from_pretrained(language_model_name,\n","                                                                   ignore_mismatched_sizes=True,\n","                                                                   output_attentions=False, output_hidden_states=False,\n","                                                                   num_labels=2) # number of the classes\n","\n","tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"sentence\"], padding=True, truncation=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["a57be2faae5d45638af3e44a914b51a4","89aafc0136e24694ba6463efb9750dee","b8aa45fb144e435a86512dc9a08850c7","bd361e230d604ea68cf0d6e5811cf727","07953d4ddf8f4fc3b0983adf6b32e2df","2674353de1af46028f3a996d7bd139c6","91cbb2a7875f46f9851c140a73cc3d63","32b8138813054c1dbbc9ffcfae09a956","804240cff4aa45c0a58ffaf623bd47e0","f94aa52c201743d2996a6cd8366faf96","2173a807b5224232bc0ec1293597e077"]},"executionInfo":{"elapsed":636,"status":"ok","timestamp":1716454869253,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"KwXqj8tct-yD","outputId":"90f27219-e611-4039-9ddf-3f096e59ad5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenize the dataset ...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6aa9607fdfc44d068b2bd45b80703918","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/872 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Tokenize the dataset ...\n","print(\"Tokenize the dataset ...\")\n","tokenized_datasets_sst2 = sst2_dataset.map(tokenize_function, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"GWmn_wLzooPe"},"source":["## Model Training\n","\n","To train a transformer model you can rely on the **Trainer** class of Huggingface (https://huggingface.co/docs/transformers/main_classes/trainer).\n","\n","The Trainer class allows you to save many lines of code, and makes your code much more readable.\n","\n","To initialize the Trainer class you have to define a **TrainerArguments** object."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ArBIUUy_vDPg"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"training_dir\",                    # output directory [Mandatory]\n","    num_train_epochs=epochs,                      # total number of training epochs\n","    per_device_train_batch_size=batch_size,       # batch size per device during training\n","    warmup_steps=500,                             # number of warmup steps for learning rate scheduler\n","    weight_decay=weight_decay,                    # strength of weight decay\n","    save_strategy=\"no\",\n","    learning_rate=learning_rate                   # learning rate\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"o4rAJRJNucX0"},"outputs":[],"source":["trainer = Trainer(\n","   model=model,\n","   args=training_args,\n","   train_dataset=tokenized_datasets_sst2[\"train\"],\n","   eval_dataset=tokenized_datasets_sst2[\"validation\"],\n","   tokenizer=tokenizer,\n","   data_collator=data_collator,\n","   compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"elapsed":392847,"status":"ok","timestamp":1716455277605,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"8ohc7fZBvjDJ","outputId":"37b419c1-fabf-4624-e6df-3e6e83ab5157"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62efe18aba2c4e74a862fb2a9c86c005","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/8419 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5944, 'grad_norm': 2.0969250202178955, 'learning_rate': 0.0001, 'epoch': 0.06}\n","{'loss': 0.7004, 'grad_norm': 1.1538499593734741, 'learning_rate': 9.368607147367092e-05, 'epoch': 0.12}\n","{'loss': 0.7024, 'grad_norm': 1.4970831871032715, 'learning_rate': 8.737214294734185e-05, 'epoch': 0.18}\n","{'loss': 0.6955, 'grad_norm': 1.297337532043457, 'learning_rate': 8.105821442101276e-05, 'epoch': 0.24}\n","{'loss': 0.6957, 'grad_norm': 0.6537973284721375, 'learning_rate': 7.474428589468367e-05, 'epoch': 0.3}\n","{'loss': 0.6904, 'grad_norm': 1.0907007455825806, 'learning_rate': 6.843035736835459e-05, 'epoch': 0.36}\n","{'loss': 0.6891, 'grad_norm': 0.5343977212905884, 'learning_rate': 6.211642884202552e-05, 'epoch': 0.42}\n","{'loss': 0.6915, 'grad_norm': 1.2975486516952515, 'learning_rate': 5.580250031569643e-05, 'epoch': 0.48}\n","{'loss': 0.6916, 'grad_norm': 3.150383949279785, 'learning_rate': 4.948857178936735e-05, 'epoch': 0.53}\n","{'loss': 0.6841, 'grad_norm': 2.475999355316162, 'learning_rate': 4.3174643263038265e-05, 'epoch': 0.59}\n","{'loss': 0.6896, 'grad_norm': 1.2350746393203735, 'learning_rate': 3.6860714736709185e-05, 'epoch': 0.65}\n","{'loss': 0.6908, 'grad_norm': 0.7417169213294983, 'learning_rate': 3.05467862103801e-05, 'epoch': 0.71}\n","{'loss': 0.6888, 'grad_norm': 0.6644601225852966, 'learning_rate': 2.423285768405102e-05, 'epoch': 0.77}\n","{'loss': 0.6904, 'grad_norm': 1.9949146509170532, 'learning_rate': 1.7918929157721937e-05, 'epoch': 0.83}\n","{'loss': 0.6868, 'grad_norm': 0.9296033382415771, 'learning_rate': 1.1605000631392853e-05, 'epoch': 0.89}\n","{'loss': 0.6822, 'grad_norm': 2.607069730758667, 'learning_rate': 5.291072105063771e-06, 'epoch': 0.95}\n","{'train_runtime': 2560.9438, 'train_samples_per_second': 26.299, 'train_steps_per_second': 3.287, 'train_loss': 0.6855314222816787, 'epoch': 1.0}\n"]},{"data":{"text/plain":["TrainOutput(global_step=8419, training_loss=0.6855314222816787, metrics={'train_runtime': 2560.9438, 'train_samples_per_second': 26.299, 'train_steps_per_second': 3.287, 'total_flos': 2206919518482660.0, 'train_loss': 0.6855314222816787, 'epoch': 1.0})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Let's Train ...\n","trainer.train()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"elapsed":4377,"status":"ok","timestamp":1716455281959,"user":{"displayName":"Luca Moroni","userId":"02572288400885355292"},"user_tz":-120},"id":"fpvMaurQvktK","outputId":"e46ebbe0-5255-4e67-dc2f-9d95966e6d76"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/dario/repos/MNLP_HW3/.mnlp/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/accuracy/accuracy.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n","/home/dario/repos/MNLP_HW3/.mnlp/lib/python3.12/site-packages/datasets/load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/f1/f1.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"739e13c727b447689058109b9f87ea71","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.7017666697502136,\n"," 'eval_accuracy': 0.5091743119266054,\n"," 'eval_f1': 0.6747720364741642,\n"," 'eval_runtime': 11.3533,\n"," 'eval_samples_per_second': 76.806,\n"," 'eval_steps_per_second': 9.601,\n"," 'epoch': 1.0}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluate the model ...\n","trainer.evaluate()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1abQ4ksp5EU9FA-ibnO4OKV1JlGpxR9SL","timestamp":1682676416498},{"file_id":"1yV8wFHpRRy3y3nnJgK1S4ZNosf7teUrC","timestamp":1653295049649}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07953d4ddf8f4fc3b0983adf6b32e2df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2173a807b5224232bc0ec1293597e077":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2674353de1af46028f3a996d7bd139c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32b8138813054c1dbbc9ffcfae09a956":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"804240cff4aa45c0a58ffaf623bd47e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89aafc0136e24694ba6463efb9750dee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2674353de1af46028f3a996d7bd139c6","placeholder":"​","style":"IPY_MODEL_91cbb2a7875f46f9851c140a73cc3d63","value":"Map: 100%"}},"91cbb2a7875f46f9851c140a73cc3d63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a57be2faae5d45638af3e44a914b51a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89aafc0136e24694ba6463efb9750dee","IPY_MODEL_b8aa45fb144e435a86512dc9a08850c7","IPY_MODEL_bd361e230d604ea68cf0d6e5811cf727"],"layout":"IPY_MODEL_07953d4ddf8f4fc3b0983adf6b32e2df"}},"b8aa45fb144e435a86512dc9a08850c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_32b8138813054c1dbbc9ffcfae09a956","max":1821,"min":0,"orientation":"horizontal","style":"IPY_MODEL_804240cff4aa45c0a58ffaf623bd47e0","value":1821}},"bd361e230d604ea68cf0d6e5811cf727":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f94aa52c201743d2996a6cd8366faf96","placeholder":"​","style":"IPY_MODEL_2173a807b5224232bc0ec1293597e077","value":" 1821/1821 [00:00&lt;00:00, 4770.56 examples/s]"}},"f94aa52c201743d2996a6cd8366faf96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
